{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled29.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jXE2Akx1mDp"
      },
      "source": [
        "#Make sure that you have all these libaries available to run the code successfully\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "from math import sqrt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import math\n",
        "from datetime import datetime\n",
        "from fbprophet import Prophet\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore',category=FutureWarning)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
        "from keras.optimizers import SGD\n",
        "from numpy import mean\n",
        "from numpy import std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gex3OM-91rEE"
      },
      "source": [
        "#loading data \n",
        "mydateparser = lambda x: datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")\n",
        "dataset = pd.read_csv('data10_25_oct.csv',sep=';', names=['Date', 'ming'], parse_dates=['Date'], date_parser=mydateparser, low_memory=False)\n",
        "#convert the data to time-series type, by taking index to be the time\n",
        "dataset=dataset.sort_values(by=['Date'],ascending=True)\n",
        "#Data visualization\n",
        "dataset.set_index('Date')[\"ming\"].plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['Real Gas Price'])\n",
        "plt.show()\n",
        "#Data preprocesssing steps: \n",
        "#Step 1 : data re-sampling \n",
        "dataset=dataset.set_index('Date').resample('5 Min').mean()\n",
        "dataset[\"ming\"].plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['Real Gas Price'])\n",
        "plt.show()\n",
        "#Step 2 : removing outliers \n",
        "## calculate summary statistics\n",
        "data_mean, data_std = mean(dataset[\"ming\"]), std(dataset[\"ming\"])\n",
        "# identify outliers\n",
        "cut_off = data_std * 2\n",
        "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
        "for index,row in dataset.iterrows():\n",
        "  if row[\"ming\"] < lower:\n",
        "    row[\"ming\"]=lower\n",
        "  elif row[\"ming\"] > upper:\n",
        "    row[\"ming\"]=upper\n",
        "#remove outliers \n",
        "outliers_removed = [x for x in dataset[\"ming\"] if x >= lower and x <= upper]\n",
        "print('Non-outlier observations: %d' % len(outliers_removed))\n",
        "#Data visualization\n",
        "dataset[\"ming\"].plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['Real Gas Price'])\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE1H1lEpG3L6"
      },
      "source": [
        "#loading data \n",
        "mydateparser = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
        "gethdata = pd.read_csv('geth.csv',sep=';', names=['Date', 'gethprice'], parse_dates=['Date'], date_parser=mydateparser, low_memory=False)\n",
        "#convert the data to time-series type, by taking index to be the time\n",
        "gethdata=gethdata.sort_values(by=['Date'],ascending=True)\n",
        "#Data visualization\n",
        "gethdata.set_index('Date')['2020-10-21 08:40:00':'2020-10-24 17:05:00'][\"gethprice\"].plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['Geth gas price'])\n",
        "plt.show()\n",
        "#Data preprocesssing steps: \n",
        "#Step 1 : data re-sampling \n",
        "gethdata=gethdata.set_index('Date')['2020-10-21 08:40:00':'2020-10-24 17:05:00'].resample('5 Min').mean()\n",
        "#Step 2 : removing outliers \n",
        "# calculate summary statistics\n",
        "data_mean, data_std = mean(gethdata[\"gethprice\"]), std(gethdata[\"gethprice\"])\n",
        "# identify outliers\n",
        "for index,row in gethdata.iterrows():\n",
        "  if row[\"gethprice\"] < lower:\n",
        "    row[\"gethprice\"]=lower\n",
        "  elif row[\"gethprice\"] > upper:\n",
        "    row[\"gethprice\"]=upper\n",
        "#remove outliers \n",
        "outliers_removed = [x for x in gethdata[\"gethprice\"] if x >= lower and x <= upper]\n",
        "print('Non-outlier observations: %d' % len(outliers_removed))\n",
        "#Data visualization\n",
        "gethdata['2020-10-21 08:40:00':'2020-10-24 17:05:00'][\"gethprice\"].plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['Geth gas price'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVNsAtS6RmIN"
      },
      "source": [
        "Our approach proposes comparing different prediction models to recommend the gas price with Geth oracle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0dvAVpWInlx"
      },
      "source": [
        "# **Prophet model  :**\n",
        "Prophet, developed by Facebook,  is an open-source tool designed for time series forecasting . It is implemented in an R library, and also a Python package (as already shown in this contest).\n",
        "\n",
        "Prophet essentially is an additive regression model that decomposes a time series into (i) a linear/logistic (piecewise) trend, (ii) an annual seasonal component, (iii) a weekly seasonal component, and (iv) an optional list of important days (such as vacations, special events, ...). The model states that it is \"robust to missing data, trend changes, and significant outliers\", which would make it well suited to this particular task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0E0dACx1uJ8"
      },
      "source": [
        "#These experiments are done without data transformation technique \n",
        "dataset1 =dataset[['ming']]\n",
        "#splitting data into Train/Test data\n",
        "training_set = dataset1['2020-10-10 00:00:00':'2020-10-21 08:35:00']\n",
        "training_set = training_set.reset_index()[['Date', 'ming']]\n",
        "testsetp = dataset1['2020-10-21 08:40:00': '2020-10-24 18:05:00']\n",
        "testsetp = testsetp.reset_index()[['Date', 'ming']]\n",
        "training_set.columns = ['ds', 'y']\n",
        "#Create Prophet Model\n",
        "m = Prophet(changepoint_prior_scale=0.0005,yearly_seasonality=False, weekly_seasonality=True, daily_seasonality=True).fit(training_set)\n",
        "#Forecast on Test Set\n",
        "future = m.make_future_dataframe(periods=978, freq='5 Min', include_history= True)\n",
        "fcst = m.predict(future)\n",
        "#forecasts visualisation\n",
        "fig = m.plot(fcst)\n",
        "fig = m.plot_components(fcst)\n",
        "real=np.array(dataset1.ming)\n",
        "real=real.reshape(-1, 1)\n",
        "pred=np.array(fcst.yhat)\n",
        "pred=pred.reshape(-1, 1)\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "real = sc.fit_transform(real)\n",
        "pred = sc.transform(pred)\n",
        "#Error Metrics On Test Set\n",
        "print('prophet MAE : %.3f'%mean_absolute_error(real, pred))\n",
        "print('prophet MSE: %.3f'%mean_squared_error(real, pred))\n",
        "print('prophet R2-score : %.3f'%r2_score(real, pred))\n",
        "print('prophet RMSE : %.3f'%sqrt(mean_squared_error(real, pred)))\n",
        "fcst=fcst.set_index('ds')\n",
        "dataset1=dataset1.reset_index()[['Date', 'ming']]\n",
        "dataset1.columns = ['ds', 'y']\n",
        "fcst = fcst.reset_index()[['ds', 'yhat']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctzPNzDhUNrv"
      },
      "source": [
        "Brief notes about how the Prophet worked in practice:\n",
        "\n",
        "data format: the prophet expects a data frame with only two columns: ds, y. The first column holds the dates, while the second contains the time series information.\n",
        "\n",
        "The parameter changepoint.prior.scale is useful for adjusting the flexibility of the trend. Raising this parameter makes the adjustment more flexible, but it also increases the uncertainty of the forecast and makes it more likely to adapt to noise. The change points in the data are automatically detected, except if they are manually specified using the change point parameter (which we do not do here).\n",
        "\n",
        "The parameters daily.seasonality=TRUE and weekly.seasonality=TRUE must be explicitly enabled and allow the prophet to notice small-scale cycles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRn17nTJ1xby"
      },
      "source": [
        "#These experiments are done with data transformation technique \n",
        "dataset1 =dataset[['ming']]\n",
        "#applying logarithmic transformation\n",
        "dataset1['ming'] = np.log(dataset1['ming'])\n",
        "#splitting data into Train/Test data\n",
        "training_set = dataset1['2020-10-10 00:00:00':'2020-10-21 08:35:00']\n",
        "training_set = training_set.reset_index()[['Date', 'ming']]\n",
        "testsetp = dataset1['2020-10-21 08:40:00': '2020-10-24 18:05:00']\n",
        "testsetp = testsetp.reset_index()[['Date', 'ming']]\n",
        "training_set.columns = ['ds', 'y']\n",
        "#Create Prophet Model\n",
        "m = Prophet(changepoint_prior_scale=0.005,yearly_seasonality=False, weekly_seasonality=True, daily_seasonality=True).fit(training_set)\n",
        "#Forecast on Test Set\n",
        "future = m.make_future_dataframe(periods=978, freq='5 Min', include_history= True)\n",
        "fcst = m.predict(future)\n",
        "#forecasts visualisation\n",
        "fig = m.plot(fcst)\n",
        "fig = m.plot_components(fcst)\n",
        "#Error Metrics On Test Set\n",
        "real=np.array(dataset1.ming)\n",
        "real=real.reshape(-1, 1)\n",
        "pred=np.array(fcst.yhat)\n",
        "pred=pred.reshape(-1, 1)\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "real = sc.fit_transform(real)\n",
        "pred = sc.transform(pred)\n",
        "print('prophet : %.3f'%mean_absolute_error(real, pred))\n",
        "print('prophet : %.3f'%mean_squared_error(real, pred))\n",
        "print('prophet : %.3f'%r2_score(real, pred))\n",
        "print('prophet : %.3f'%sqrt(mean_squared_error(real, pred)))\n",
        "fcst['yhat']=np.exp(fcst['yhat'])\n",
        "dataset1['ming'] =np.exp(dataset1['ming'])\n",
        "fcst=fcst.set_index('ds')\n",
        "dataset1=dataset1.reset_index()[['Date', 'ming']]\n",
        "dataset1.columns = ['ds', 'y']\n",
        "fcst = fcst.reset_index()[['ds', 'yhat']]\n",
        "#inverse the log transformation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVDDyGbI10tq"
      },
      "source": [
        "#visualize prophet prediction\n",
        "metric_df = fcst.set_index('ds')[['yhat']].join(dataset1.set_index('ds').y).reset_index()\n",
        "metric_df.y=metric_df.y.fillna(0)\n",
        "print(metric_df.tail())\n",
        "plt.legend(['true' , 'prdicted'])\n",
        "metric_df.set_index('ds').y.plot(figsize=(16,6),legend=True,grid=True)\n",
        "metric_df.set_index('ds').yhat.plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['real gasprice' , 'predicted gas price'])\n",
        "plt.title('Prophet Gas Price Predicton ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW8dLYhs117L"
      },
      "source": [
        "#visualize prophet prediction over training and testing  period \n",
        "plt.legend(['true' , 'predicted'])\n",
        "metric_df.set_index('ds')['2020-10-10 00:00:00':'2020-10-21 08:35:00'].y.plot(figsize=(16,6),legend=True,grid=True)\n",
        "metric_df.set_index('ds')['2020-10-10 00:00:00':'2020-10-21 08:35:00'].yhat.plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['real gasprice' , 'predicted gas price'])\n",
        "plt.title('Prophet Gas Price Predicton over training period')\n",
        "plt.show()\n",
        "plt.legend(['true' , 'prdicted'])\n",
        "metric_df.set_index('ds')['2020-10-21 08:40:00': '2020-10-24 18:05:00'].y.plot(figsize=(16,6),legend=True,grid=True)\n",
        "metric_df.set_index('ds')['2020-10-21 08:40:00': '2020-10-24 18:05:00'].yhat.plot(figsize=(16,6),legend=True,grid=True)\n",
        "plt.legend(['real gasprice' , 'predicted gas price'])\n",
        "plt.title('Prophet Gas Price Predicton over testing period')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j072ViehLVf8"
      },
      "source": [
        "GRU is a simplification of the LSTM unit, it has been demonstrated to work in a similar way in many tasks, while reducing complexity. GRU surpassed the LSTM in many cases. Therefore, if the data scale is large, LSTM may be more efficient. In the GRU, the input gate and the forgetting gate of LSTM have been merged into a single gate: the update gate. This unit controls the amount of information from the previous hidden state to the next hidden state, allowing long-term dependencies to be captured directly without the need for the cell state. To control the redundant information, there is a second gate, the reset gate that decides how much previous hidden states should be forgotten. The specificity of these gates is that they can be trained to keep information from a long time ago, without washing it through time or removing any not relevant information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8OMG8Pq4cn9"
      },
      "source": [
        "dataset2 = dataset[['ming']]\n",
        "# removing missing value rows\n",
        "dataset2 = dataset2.dropna() \n",
        "#splitting data into Train/Test data\n",
        "training_set = dataset2['2020-10-10 00:00:00':'2020-10-21 08:35:00']\n",
        "test_set = dataset2['2020-10-21 07:20:00':'2020-10-24 17:05:00']\n",
        "#applying min-max normalization\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_set = sc.fit_transform(training_set)\n",
        "test_set = sc.transform(test_set)\n",
        "training_set = np.array(training_set)\n",
        "test_set = np.array(test_set)\n",
        "#Create x, y test and train data windows and into input and outputs\n",
        "X_train = []\n",
        "Y_train = []\n",
        "previous = 15\n",
        "# reshape input to be 2D [samples, timesteps]\n",
        "for i in range(len(training_set)-previous-1):\n",
        "    X_train.append(training_set[i:i+previous])\n",
        "    Y_train.append(training_set[i+previous])\n",
        "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
        "Y_train = np.reshape(Y_train, (Y_train.shape[0],-1))\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
        "X_train.shape, Y_train.shape\n",
        "X_test = []\n",
        "Y_test = []\n",
        "for i in range(len(test_set)-previous-1):\n",
        "    X_test.append(test_set[i:i+previous])\n",
        "    Y_test.append(test_set[i+previous])\n",
        "X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
        "Y_test = np.reshape(Y_test, (Y_test.shape[0],-1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
        "#Create GRU Model\n",
        "model = Sequential()\n",
        "model.add(GRU(units=15,activation='tanh',input_shape=(X_train.shape[1], X_train.shape[2]),dropout=0.01))\n",
        "model.add(Dense(1))\n",
        "opt = SGD(lr=0.01, decay=0.0001)\n",
        "model.compile(loss='mean_absolute_error', optimizer=opt)\n",
        "# fit network\n",
        "history = model.fit(X_train, Y_train, epochs=500,batch_size=128,shuffle=False,validation_split=0.10,verbose=0)\n",
        "# summarize history for loss\n",
        "train_maeG = modelG.evaluate(X_train,Y_train)\n",
        "test_maeG = modelG.evaluate(X_test, Y_test)\n",
        "print('Train: %.3f, Test: %.3f' % (train_maeG, test_maeG))\n",
        "#visualize results \n",
        "plt.plot(history.epoch, history.history['loss'])\n",
        "plt.plot(history.epoch , history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "036R9I2P77Hm"
      },
      "source": [
        "# make a prediction for training data\n",
        "trainGRU = model.predict(X_train)\n",
        "#calculate error rates \n",
        "maeGRUTR=mean_absolute_error(Y_train, trainGRU)\n",
        "mseGRUTR=mean_squared_error(Y_train, trainGRU)\n",
        "r2GRUTR=r2_score(Y_train, trainGRU)\n",
        "rmseGRUTR=sqrt(mean_squared_error(Y_train, trainGRU))\n",
        "print('gru : %.3f'%maeGRUTR)\n",
        "print('gru : %.3f'%mseGRUTR)\n",
        "print('gru : %.3f'%r2GRUTR)\n",
        "print('gru : %.3f'%rmseGRUTR)\n",
        "print(trainGRU.shape)\n",
        "# invert scaling for forecast and real \n",
        "trainGRU = sc.inverse_transform(trainGRU)\n",
        "Y_train = sc.inverse_transform(Y_train)\n",
        "#visualaize forecastings \n",
        "plt.figure(figsize=(18,5))\n",
        "plt.plot(Y_train, color='blue',label='Predicted '+' Gas Price')\n",
        "plt.plot(trainGRU, color='yellow',label='real '+' Gas Price')\n",
        "plt.title(' Gas Price Prediction(GRU)')\n",
        "plt.xlabel('Time')\n",
        "plt.grid()\n",
        "plt.ylabel(' Gas Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdaJw2UT8lE2"
      },
      "source": [
        "testGRU = model.predict(X_test)\n",
        "#calculate error rates \n",
        "maeGRUTS=mean_absolute_error(Y_test, testGRU)\n",
        "mseGRUTS=mean_squared_error(Y_test, testGRU)\n",
        "r2GRUTS=r2_score(Y_test, testGRU)\n",
        "rmseGRUTS=sqrt(mean_squared_error(Y_test, testGRU))\n",
        "print('gru : %.3f'%maeGRUTS)\n",
        "print('gru : %.3f'%mseGRUTS)\n",
        "print('gru : %.3f'%r2GRUTS)\n",
        "print('gru : %.3f'%rmseGRUTS)\n",
        "print(testGRU.shape)\n",
        "# invert scaling for forecast and real\n",
        "testGRU = sc.inverse_transform(testGRU)\n",
        "Y_test = sc.inverse_transform(Y_test)\n",
        "#visualaize forecastings\n",
        "plt.figure(figsize=(18,5))\n",
        "plt.plot(Y_test, color='blue',label='Predicted '+' Gas Price')\n",
        "plt.plot(testGRU, color='yellow',label='real '+' Gas Price')\n",
        "plt.title(' Gas Price Prediction(GRU)')\n",
        "plt.xlabel('Time')\n",
        "plt.grid()\n",
        "plt.ylabel(' Gas Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m3b4TQopXhT"
      },
      "source": [
        "LSTM stands for long short term memory. It is a model or architecture that extends the memory of recurrent neural networks. Typically, recurrent neural networks have ‘short term memory’ in that they use persistent previous information to be used in the current neural network. Essentially, the previous information is used in the present task. That means we do not have a list of all of the previous information available for the neural node. LSTM introduces long-term memory into recurrent neural networks. It mitigates the vanishing gradient problem, which is where the neural network stops learning because the updates to the various weights within a given neural network become smaller and smaller. It does this by using a series of ‘gates’.These are contained in memory blocks which are connected through layers. LSTM work There are three types of gates within a unit: Input Gate: Scales input to cell (write) Output Gate: Scales output to cell (read) Forget Gate: Scales old cell value (reset) Each gate is like a switch that controls the read/write, thus incorporating the long-term memory function into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8KYW1KY15d0"
      },
      "source": [
        "dataset2 = dataset[['ming']]\n",
        "# removing missing value rows\n",
        "dataset2 = dataset2.dropna()\n",
        "#splitting data into Train/Test data\n",
        "training_set = dataset2['2020-10-10 00:00:00':'2020-10-21 08:35:00']\n",
        "test_set = dataset2['2020-10-21 07:20:00':'2020-10-24 17:05:00']\n",
        "#applying min-max normalization \n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_set = sc.fit_transform(training_set)\n",
        "test_set = sc.transform(test_set)\n",
        "#Create x, y test and train data windows and into input and outputs\n",
        "training_set = np.array(training_set)\n",
        "test_set = np.array(test_set)\n",
        "x_train = []\n",
        "y_train = []\n",
        "previous =15\n",
        "for i in range(len(training_set)-previous-1):\n",
        "    x_train.append(training_set[i:i+previous])\n",
        "    y_train.append(training_set[i+previous])\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "# reshape input to be 3D [samples, timesteps]\n",
        "y_train = np.reshape(y_train, (y_train.shape[0],-1))\n",
        "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
        "x_train.shape, y_train.shape\n",
        "x_test = []\n",
        "y_test = []\n",
        "for i in range(len(test_set)-previous-1):\n",
        "    x_test.append(test_set[i:i+previous])\n",
        "    y_test.append(test_set[i+previous])\n",
        "x_test, y_test = np.array(x_test), np.array(y_test)\n",
        "# reshape input to be 2D [samples, timesteps]\n",
        "y_test = np.reshape(y_test, (y_test.shape[0],-1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
        "#Create LSTM Model\n",
        "modelL = Sequential()\n",
        "modelL.add(LSTM(units =15,activation='tanh',input_shape=(x_train.shape[1], x_train.shape[2]),dropout=0.01))\n",
        "modelL.add(Dense(1))\n",
        "opt = SGD(lr=0.01, decay=0.0001)\n",
        "modelL.compile(loss='mean_absolute_error', optimizer=opt)\n",
        "# fit network\n",
        "history2 = modelL.fit(x_train, y_train, epochs=500,batch_size=112,validation_split=0.10,shuffle=False,verbose=0)\n",
        "# summarize history for loss\n",
        "train_mseL = modelL.evaluate(x_train,y_train)\n",
        "test_mseL = modelL.evaluate(x_test, y_test)\n",
        "print('Train: %.3f, Test: %.3f' % (train_mseL, test_mseL))\n",
        "#visualize results \n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37E4HsHg2ArD"
      },
      "source": [
        "# make a prediction for training data\n",
        "trainLSTM = modelL.predict(x_train)\n",
        "#calculate error rates \n",
        "maeLSTMTR=mean_absolute_error(y_train, trainLSTM)\n",
        "mseLSTMTR=mean_squared_error(y_train, trainLSTM)\n",
        "r2LSTMTR=r2_score(y_train, trainLSTM)\n",
        "rmseLSTMTR=sqrt(mean_squared_error(y_train, trainLSTM))\n",
        "print('LSTM : %.3f'%maeLSTMTR)\n",
        "print('LSTM : %.3f'%mseLSTMTR)\n",
        "print('LSTM : %.3f'%r2LSTMTR)\n",
        "print('LSTM : %.3f'%rmseLSTMTR)\n",
        "print(trainLSTM.shape)\n",
        "# invert scaling for forecast and real \n",
        "trainLSTM = sc.inverse_transform(trainLSTM)\n",
        "y_train = sc.inverse_transform(y_train)\n",
        "plt.figure(figsize=(18,5))\n",
        "#visualaize forecastings \n",
        "plt.plot(y_train, color='blue',label='Predicted '+' Gas Price')\n",
        "plt.plot(trainLSTM, color='red',label='real '+' Gas Price')\n",
        "plt.title(' Gas Price Prediction(LSTM)')\n",
        "plt.xlabel('Time')\n",
        "plt.grid()\n",
        "plt.ylabel(' Gas Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcqv2_uZ2F3E"
      },
      "source": [
        "# make a prediction for training data\n",
        "testLSTM = modelL.predict(x_test)\n",
        "#calculate error rates \n",
        "maeLSTMTS=mean_absolute_error(y_test, testLSTM)\n",
        "mseLSTMTS=mean_squared_error(y_test, testLSTM)\n",
        "r2LSTMTS=r2_score(y_test, testLSTM)\n",
        "rmseLSTMTS=sqrt(mean_squared_error(y_test, testLSTM))\n",
        "print('LSTM : %.3f'%maeLSTMTS)\n",
        "print('LSTM : %.3f'%mseLSTMTS)\n",
        "print('LSTM : %.3f'%r2LSTMTS)\n",
        "print('LSTM : %.3f'%rmseLSTMTS)\n",
        "#calculate Geth error rates \n",
        "gethdata = gethdata.reset_index()[['Date', 'gethprice']]\n",
        "geth=np.array(gethdata['gethprice'])\n",
        "geth = sc.transform(geth.reshape(-1,1))\n",
        "maeGeth=mean_absolute_error(y_test, geth)\n",
        "print('Geth : %.3f'%mean_absolute_error(y_test, geth))\n",
        "print('Geth : %.3f'%mean_squared_error(y_test, geth))\n",
        "print('Geth : %.3f'%r2_score(y_test, geth))\n",
        "print('Geth : %.3f'%sqrt(mean_squared_error(y_test, geth)))\n",
        "# invert scaling for forecast and real \n",
        "testLSTM = sc.inverse_transform(testLSTM)\n",
        "y_test = sc.inverse_transform(y_test)\n",
        "#visualaize forecastings \n",
        "plt.figure(figsize=(18,5))\n",
        "plt.plot(y_test, color='blue',label='Predicted '+' Gas Price')\n",
        "plt.plot(testLSTM, color='red',label='real '+' Gas Price')\n",
        "plt.title(' Gas Price Prediction(LSTM)')\n",
        "plt.xlabel('Time')\n",
        "plt.grid()\n",
        "plt.ylabel(' Gas Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smw2ciFy2Kxr"
      },
      "source": [
        "#visualize of different prediction models\n",
        "gethdata['predP']=fcst['yhat'][0:966]\n",
        "gethdata['predL']=testLSTM[0:966]\n",
        "gethdata['predG']=testGRU[0:966]\n",
        "gethdata['real']=y_test[0:966]\n",
        "gethdata.set_index('Date').gethprice.plot(figsize=(18,6),color='g',legend=True,grid=True)\n",
        "gethdata.set_index('Date').real.plot(figsize=(18,6),color='b',legend=True,grid=True)\n",
        "gethdata.set_index('Date').predL.plot(figsize=(18,6),color='r',legend=True,grid=True)\n",
        "gethdata.set_index('Date').predG.plot(figsize=(18,6),color='y',legend=True,grid=True)\n",
        "gethdata.set_index('Date').predP.plot(figsize=(18,6),color='orange',legend=True,grid=True)\n",
        "plt.legend(['Geth' , 'real','predLSTM','predGRU','predProphet'])\n",
        "plt.title(' Gas Price methods comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}